{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[SQL Micro-Course Home Page](https://www.kaggle.com/learn/SQL)**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n[Stack Overflow](https://stackoverflow.com/) is a widely beloved question and answer site for technical questions. You'll probably use it yourself as you keep using SQL (or any programming language). \n\nTheir data is publicly available. What cool things do you think it would be useful for?\n\nHere's one idea:\nYou could set up a service that identifies the Stack Overflow users who have demonstrated expertise with a specific technology by answering related questions about it, so someone could hire those experts for in-depth help.\n\nIn this exercise, you'll write the SQL queries that might serve as the foundation for this type of service.\n\nAs usual, run the following cell to set up our feedback system before moving on."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.sql.ex6 import *\nprint(\"Setup Complete\")","execution_count":1,"outputs":[{"output_type":"stream","text":"Using Kaggle's public dataset BigQuery integration.\nSetup Complete\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Run the next cell to fetch the `stackoverflow` dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"from google.cloud import bigquery\n\n# Create a \"Client\" object\nclient = bigquery.Client()\n\n# Construct a reference to the \"stackoverflow\" dataset\ndataset_ref = client.dataset(\"stackoverflow\", project=\"bigquery-public-data\")\n\n# API request - fetch the dataset\ndataset = client.get_dataset(dataset_ref)","execution_count":2,"outputs":[{"output_type":"stream","text":"Using Kaggle's public dataset BigQuery integration.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Exercises\n\n### 1) Explore the data\n\nBefore writing queries or **JOIN** clauses, you'll want to see what tables are available. \n\n*Hint*: Tab completion is helpful whenever you can't remember a command. Type `client.` and then hit the tab key. Don't forget the period before hitting tab."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a list of available tables \ntables = list(client.list_tables(dataset))\nlist_of_tables = [table.table_id for table in tables]\n\n# Print your answer\nprint(list_of_tables)\n\n# Check your answer\nq_1.check()","execution_count":4,"outputs":[{"output_type":"stream","text":"['badges', 'comments', 'post_history', 'post_links', 'posts_answers', 'posts_moderator_nomination', 'posts_orphaned_tag_wiki', 'posts_privilege_wiki', 'posts_questions', 'posts_tag_wiki', 'posts_tag_wiki_excerpt', 'posts_wiki_placeholder', 'stackoverflow_posts', 'tags', 'users', 'votes']\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.25, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 82, \"questionId\": \"1_ListSOTables\", \"learnToolsVersion\": \"0.2.13\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For the solution, uncomment the line below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_1.solution()","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"learnTutorialId\": 82, \"questionId\": \"1_ListSOTables\", \"learnToolsVersion\": \"0.2.13\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\n# Get a list of available tables \ntables = list(client.list_tables(dataset))\nlist_of_tables = [table.table_id for table in tables] \n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\n# Get a list of available tables \ntables = list(client.list_tables(dataset))\nlist_of_tables = [table.table_id for table in tables] \n\n```"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2) Review relevant tables\n\nIf you are interested in people who answer questions on a given topic, the `posts_answers` table is a natural place to look. Run the following cell, and look at the output."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Construct a reference to the \"posts_answers\" table\nanswers_table_ref = dataset_ref.table(\"posts_answers\")\n\n# API request - fetch the table\nanswers_table = client.get_table(answers_table_ref)\n\n# Preview the first five lines of the \"posts_answers\" table\nclient.list_rows(answers_table, max_results=5).to_dataframe()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"         id                                               body ...   score tags\n0   4058478  <p>Restart netbeans. I had a similar problem a... ...       1     \n1   4187003  <p>All URLs within the page are relative to th... ...       0     \n2   8621524  <p>It sounds like responsiveness to the API ca... ...       1     \n3   6553106  <p>Yes. That's the (one of) the points of Hash... ...       0     \n4  23032552  <p>I think I found the problem. I changed the ... ...       3     \n\n[5 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>body</th>\n      <th>comment_count</th>\n      <th>community_owned_date</th>\n      <th>creation_date</th>\n      <th>last_activity_date</th>\n      <th>last_edit_date</th>\n      <th>last_editor_display_name</th>\n      <th>last_editor_user_id</th>\n      <th>owner_display_name</th>\n      <th>owner_user_id</th>\n      <th>parent_id</th>\n      <th>post_type_id</th>\n      <th>score</th>\n      <th>tags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4058478</td>\n      <td>&lt;p&gt;Restart netbeans. I had a similar problem a...</td>\n      <td>2</td>\n      <td>None</td>\n      <td>2010-10-30 11:28:36.983000+00:00</td>\n      <td>2010-10-30 11:28:36.983000+00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>None</td>\n      <td></td>\n      <td>409468.0</td>\n      <td>4057995</td>\n      <td>2</td>\n      <td>1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4187003</td>\n      <td>&lt;p&gt;All URLs within the page are relative to th...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2010-11-15 17:16:15.927000+00:00</td>\n      <td>2010-11-15 17:16:15.927000+00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>None</td>\n      <td></td>\n      <td>439213.0</td>\n      <td>4184800</td>\n      <td>2</td>\n      <td>0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8621524</td>\n      <td>&lt;p&gt;It sounds like responsiveness to the API ca...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2011-12-23 23:25:45.430000+00:00</td>\n      <td>2011-12-23 23:25:45.430000+00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>None</td>\n      <td></td>\n      <td>1114079.0</td>\n      <td>8595650</td>\n      <td>2</td>\n      <td>1</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6553106</td>\n      <td>&lt;p&gt;Yes. That's the (one of) the points of Hash...</td>\n      <td>2</td>\n      <td>None</td>\n      <td>2011-07-01 20:51:33.830000+00:00</td>\n      <td>2011-07-01 20:51:33.830000+00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>None</td>\n      <td></td>\n      <td>13956.0</td>\n      <td>6553067</td>\n      <td>2</td>\n      <td>0</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23032552</td>\n      <td>&lt;p&gt;I think I found the problem. I changed the ...</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2014-04-12 15:43:59.437000+00:00</td>\n      <td>2014-04-12 15:43:59.437000+00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>None</td>\n      <td>user3413108</td>\n      <td>NaN</td>\n      <td>22366517</td>\n      <td>2</td>\n      <td>3</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"It isn't clear yet how to find users who answered questions on any given topic. But `posts_answers` has a `parent_id` column. If you are familiar with the Stack Overflow site, you might figure out that the `parent_id` is the question each post is answering.\n\nLook at `posts_questions` using the cell below."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Construct a reference to the \"posts_questions\" table\nquestions_table_ref = dataset_ref.table(\"posts_questions\")\n\n# API request - fetch the table\nquestions_table = client.get_table(questions_table_ref)\n\n# Preview the first five lines of the \"posts_questions\" table\nclient.list_rows(questions_table, max_results=5).to_dataframe()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"         id    ...     view_count\n0  23280293    ...            266\n1   5787776    ...          10505\n2  51899406    ...             53\n3  29219176    ...            427\n4  45545053    ...             30\n\n[5 rows x 19 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>body</th>\n      <th>accepted_answer_id</th>\n      <th>answer_count</th>\n      <th>comment_count</th>\n      <th>community_owned_date</th>\n      <th>creation_date</th>\n      <th>favorite_count</th>\n      <th>last_activity_date</th>\n      <th>last_edit_date</th>\n      <th>last_editor_display_name</th>\n      <th>last_editor_user_id</th>\n      <th>owner_display_name</th>\n      <th>owner_user_id</th>\n      <th>post_type_id</th>\n      <th>score</th>\n      <th>tags</th>\n      <th>view_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23280293</td>\n      <td>Jasper report data summary</td>\n      <td>&lt;p&gt;I am trying to create a report to display a...</td>\n      <td>23373319.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>None</td>\n      <td>2014-04-24 21:33:46.787000+00:00</td>\n      <td>NaN</td>\n      <td>2014-05-01 13:37:52.027000+00:00</td>\n      <td>2014-05-01 13:37:52.027000+00:00</td>\n      <td></td>\n      <td>321731</td>\n      <td></td>\n      <td>1214943</td>\n      <td>1</td>\n      <td>0</td>\n      <td>filter|jasper-reports|summary</td>\n      <td>266</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5787776</td>\n      <td>A worthy developer-friendly alternative to PayPal</td>\n      <td>&lt;p&gt;I understand payments are a tricky thing, b...</td>\n      <td>NaN</td>\n      <td>8</td>\n      <td>9</td>\n      <td>None</td>\n      <td>2011-04-26 08:28:37.397000+00:00</td>\n      <td>40.0</td>\n      <td>2013-03-19 01:57:09.860000+00:00</td>\n      <td>2013-03-19 01:57:09.860000+00:00</td>\n      <td></td>\n      <td>772853</td>\n      <td></td>\n      <td>50841</td>\n      <td>1</td>\n      <td>95</td>\n      <td>paypal|payment-gateway|payment|credit-card</td>\n      <td>10505</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>51899406</td>\n      <td>Why does adding a destructor (even empty) brea...</td>\n      <td>&lt;p&gt;I am making a class to store a reference to...</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>None</td>\n      <td>2018-08-17 16:17:18.367000+00:00</td>\n      <td>NaN</td>\n      <td>2018-08-17 17:08:03.690000+00:00</td>\n      <td>2018-08-17 17:08:03.690000+00:00</td>\n      <td></td>\n      <td>241631</td>\n      <td></td>\n      <td>3662349</td>\n      <td>1</td>\n      <td>3</td>\n      <td>c++|c++11|templates|perfect-forwarding</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>29219176</td>\n      <td>Java Math.pow(x,2.0) vs Math.pow(x,2.0000001) ...</td>\n      <td>&lt;p&gt;I am trying to compare performance of &lt;code...</td>\n      <td>29232947.0</td>\n      <td>1</td>\n      <td>8</td>\n      <td>None</td>\n      <td>2015-03-23 19:55:25.693000+00:00</td>\n      <td>2.0</td>\n      <td>2016-07-19 21:48:22.440000+00:00</td>\n      <td>2016-07-19 21:48:22.440000+00:00</td>\n      <td></td>\n      <td>2753863</td>\n      <td></td>\n      <td>2739693</td>\n      <td>1</td>\n      <td>5</td>\n      <td>java|performance</td>\n      <td>427</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>45545053</td>\n      <td>rioBufferWrite function Redis updating position</td>\n      <td>&lt;p&gt;When I am reading the code of &lt;a href=\"http...</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>None</td>\n      <td>2017-08-07 10:46:21.007000+00:00</td>\n      <td>NaN</td>\n      <td>2017-08-07 10:57:45.507000+00:00</td>\n      <td>2017-08-07 10:57:45.507000+00:00</td>\n      <td></td>\n      <td>8051589</td>\n      <td></td>\n      <td>7700616</td>\n      <td>1</td>\n      <td>1</td>\n      <td>c|redis</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Are there any fields that identify what topic or technology each question is about? If so, how could you find the IDs of users who answered questions about a specific topic?\n\nThink about it, and then check the solution by running the code in the next cell."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_2.solution()","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 82, \"questionId\": \"2_HowToFindExperts\", \"learnToolsVersion\": \"0.2.13\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n`posts_questions` has a column called `tags` which lists the topics/technologies each question is about.\n\n`posts_answers` has a column called `parent_id` which identifies the ID of the question each answer is responding to.\n`posts_answers` also has an `owner_user_id` column which specifies the ID of the user who answered the question.\n\nYou can join these two tables to:\n- determine the `tags` for each answer, and then\n- select the `owner_user_id` of the answers on the desired tag.\n\nThis is exactly what you will do over the next few questions.","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n`posts_questions` has a column called `tags` which lists the topics/technologies each question is about.\n\n`posts_answers` has a column called `parent_id` which identifies the ID of the question each answer is responding to.\n`posts_answers` also has an `owner_user_id` column which specifies the ID of the user who answered the question.\n\nYou can join these two tables to:\n- determine the `tags` for each answer, and then\n- select the `owner_user_id` of the answers on the desired tag.\n\nThis is exactly what you will do over the next few questions.\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 3) Selecting the right questions\n\nA lot of this data is text. \n\nWe'll explore one last technique in this course which you can apply to this text.\n\nA **WHERE** clause can limit your results to rows with certain text using the **LIKE** feature. For example, to select just the third row of the `pets` table from the tutorial, we could use the query in the picture below.\n\n![](https://i.imgur.com/RccsXBr.png) \n\nYou can also use `%` as a \"wildcard\" for any number of characters. So you can also get the third row with:\n\n```\nquery = \"\"\"\n        SELECT * \n        FROM `bigquery-public-data.pet_records.pets` \n        WHERE Name LIKE '%ipl%'\n        \"\"\"\n```\n\nTry this yourself. Write a query that selects the `id`, `title` and `owner_user_id` columns from the `posts_questions` table. \n- Restrict the results to rows that contain the word \"bigquery\" in the `tags` column. \n- Include rows where there is other text in addition to the word \"bigquery\" (e.g., if a row has a tag \"bigquery-sql\", your results should include that too)."},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_query = \"\"\"\n                  SELECT id, title, owner_user_id\n                  FROM `bigquery-public-data.stackoverflow.posts_questions`\n                  WHERE tags LIKE '%bigquery%'\n                  \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)\nquestions_query_job = client.query(questions_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nquestions_results = questions_query_job.to_dataframe()\n\n# Preview results\nprint(questions_results.head())\n\n# Check your answer\nq_3.check()","execution_count":9,"outputs":[{"output_type":"error","ename":"BadRequest","evalue":"400 POST https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/jobs: Invalid value at 'job.configuration.query.maximum_bytes_billed.value' (TYPE_INT64), \"1000000000.0\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-377e48bb51d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# your quota, with the limit set to 1 GB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msafe_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryJobConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaximum_bytes_billed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mquestions_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# API request - run the query, and return a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mjob_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_JobReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0mquery_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# job has an ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         api_response = client._call_api(\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_api_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         )\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadRequest\u001b[0m: 400 POST https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/jobs: Invalid value at 'job.configuration.query.maximum_bytes_billed.value' (TYPE_INT64), \"1000000000.0\""]}]},{"metadata":{},"cell_type":"markdown","source":"For a hint or the solution, uncomment the appropriate line below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_3.hint()\nq_3.solution()","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"learnTutorialId\": 82, \"questionId\": \"3_SelectRightQuestions\", \"learnToolsVersion\": \"0.2.13\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: Your **WHERE** clause should be `WHERE tags LIKE '%bigquery%'`.","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> Your **WHERE** clause should be `WHERE tags LIKE '%bigquery%'`."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 82, \"questionId\": \"3_SelectRightQuestions\", \"learnToolsVersion\": \"0.2.13\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\nquestions_query = \"\"\"\n                  SELECT id, title, owner_user_id\n                  FROM `bigquery-public-data.stackoverflow.posts_questions`\n                  WHERE tags LIKE '%bigquery%'\n                  \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)\nquestions_query_job = client.query(questions_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nquestions_results = questions_query_job.to_dataframe()\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\nquestions_query = \"\"\"\n                  SELECT id, title, owner_user_id\n                  FROM `bigquery-public-data.stackoverflow.posts_questions`\n                  WHERE tags LIKE '%bigquery%'\n                  \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)\nquestions_query_job = client.query(questions_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nquestions_results = questions_query_job.to_dataframe()\n\n```"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 4) Your first join\nNow that you have a query to select questions on any given topic (in this case, you chose \"bigquery\"), you can find the answers to those questions with a **JOIN**.  \n\nWrite a query that returns the `id`, `body` and `owner_user_id` columns from the `posts_answers` table for answers to \"bigquery\"-related questions. \n- You should have one row in your results for each answer to a question that has \"bigquery\" in the tags.  \n- Remember you can get the tags for a question from the `tags` column in the `posts_questions` table.\n\nHere's a reminder of what a **JOIN** looked like in the tutorial:\n```\nquery = \"\"\"\n        SELECT p.Name AS Pet_Name, o.Name AS Owner_Name\n        FROM `bigquery-public-data.pet_records.pets` as p\n        INNER JOIN `bigquery-public-data.pet_records.owners` as o \n            ON p.ID = o.Pet_ID\n        \"\"\"\n```\n\nIt may be useful to scroll up and review the first several rows of the `posts_answers` and `posts_questions` tables.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"answers_query = \"\"\"\n                SELECT a.id, a.body, a.owner_user_id\n                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q \n                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                    ON q.id = a.parent_id\n                WHERE q.tags LIKE '%bigquery%'\n                \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)\nanswers_query_job = client.query(answers_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nanswers_results = answers_query_job.to_dataframe()\n\n# Preview results\nprint(answers_results.head())\n\n# Check your answer\nq_4.check()","execution_count":11,"outputs":[{"output_type":"error","ename":"BadRequest","evalue":"400 POST https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/jobs: Invalid value at 'job.configuration.query.maximum_bytes_billed.value' (TYPE_INT64), \"1000000000.0\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-83108d42d856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# your quota, with the limit set to 1 GB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msafe_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryJobConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaximum_bytes_billed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0manswers_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# API request - run the query, and return a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mjob_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_JobReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0mquery_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# job has an ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         api_response = client._call_api(\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_api_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         )\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadRequest\u001b[0m: 400 POST https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/jobs: Invalid value at 'job.configuration.query.maximum_bytes_billed.value' (TYPE_INT64), \"1000000000.0\""]}]},{"metadata":{},"cell_type":"markdown","source":"For a hint or the solution, uncomment the appropriate line below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_4.hint()\nq_4.solution()","execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"learnTutorialId\": 82, \"questionId\": \"4_FirstJoin\", \"learnToolsVersion\": \"0.2.13\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: \nDo an **INNER JOIN** between `bigquery-public-data.stackoverflow.posts_questions` and `bigquery-public-data.stackoverflow.posts_answers`.\n\nGive `post_questions` an alias of `q`, and use `a` as an alias for `posts_answers`. The **ON** part of your join is `q.id = a.parent_id`.","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> \nDo an **INNER JOIN** between `bigquery-public-data.stackoverflow.posts_questions` and `bigquery-public-data.stackoverflow.posts_answers`.\n\nGive `post_questions` an alias of `q`, and use `a` as an alias for `posts_answers`. The **ON** part of your join is `q.id = a.parent_id`.\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 82, \"questionId\": \"4_FirstJoin\", \"learnToolsVersion\": \"0.2.13\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\nanswers_query = \"\"\"\n                SELECT a.id, a.body, a.owner_user_id\n                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q \n                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                    ON q.id = a.parent_id\n                WHERE q.tags LIKE '%bigquery%'\n                \"\"\"\n                \n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)\nanswers_query_job = client.query(answers_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nanswers_results = answers_query_job.to_dataframe()\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\nanswers_query = \"\"\"\n                SELECT a.id, a.body, a.owner_user_id\n                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q \n                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                    ON q.id = a.parent_id\n                WHERE q.tags LIKE '%bigquery%'\n                \"\"\"\n                \n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)\nanswers_query_job = client.query(answers_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nanswers_results = answers_query_job.to_dataframe()\n\n```"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 5) Answer the question\nYou have the merge you need. But you want a list of users who have answered many questions... which requires more work beyond your previous result.\n\nWrite a new query that has a single row for each user who answered at least one question with a tag that includes the string \"bigquery\". Your results should have two columns:\n- `user_id` - contains the `owner_user_id` column from the `posts_answers` table\n- `number_of_answers` - contains the number of answers the user has written to \"bigquery\"-related questions"},{"metadata":{"trusted":true},"cell_type":"code","source":"bigquery_experts_query = \"\"\"\n                         SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n                         FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n                         INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                             ON q.id = a.parent_Id\n                         WHERE q.tags LIKE '%bigquery%'\n                         GROUP BY a.owner_user_id\n                         \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)\nbigquery_experts_query_job = client.query(bigquery_experts_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nbigquery_experts_results = bigquery_experts_query_job.to_dataframe()\n\n# Preview results\nprint(bigquery_experts_results.head())\n\n# Check your answer\nq_5.check()","execution_count":13,"outputs":[{"output_type":"error","ename":"BadRequest","evalue":"400 POST https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/jobs: Invalid value at 'job.configuration.query.maximum_bytes_billed.value' (TYPE_INT64), \"1000000000.0\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-ee3bf28f1e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# your quota, with the limit set to 1 GB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msafe_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryJobConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaximum_bytes_billed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbigquery_experts_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigquery_experts_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# API request - run the query, and return a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mjob_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_JobReference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0mquery_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36m_begin\u001b[0;34m(self, client, retry)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;31m# job has an ID.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         api_response = client._call_api(\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_api_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         )\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_RETRY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/google/cloud/_http.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadRequest\u001b[0m: 400 POST https://dp.kaggle.net/bigquery/v2/projects/kaggle-161607/jobs: Invalid value at 'job.configuration.query.maximum_bytes_billed.value' (TYPE_INT64), \"1000000000.0\""]}]},{"metadata":{},"cell_type":"markdown","source":"For a hint or the solution, uncomment the appropriate line below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_5.hint()\nq_5.solution()","execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"learnTutorialId\": 82, \"questionId\": \"5_BigQueryExperts\", \"learnToolsVersion\": \"0.2.13\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: Start with `SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers`","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> Start with `SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers`"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 2, \"learnTutorialId\": 82, \"questionId\": \"5_BigQueryExperts\", \"learnToolsVersion\": \"0.2.13\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\nbigquery_experts_query = \"\"\"\n                         SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n                         FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n                         INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                             ON q.id = a.parent_Id\n                         WHERE q.tags LIKE '%bigquery%'\n                         GROUP BY a.owner_user_id\n                         \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)\nbigquery_experts_query_job = client.query(bigquery_experts_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nbigquery_experts_results = bigquery_experts_query_job.to_dataframe()\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\nbigquery_experts_query = \"\"\"\n                         SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n                         FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n                         INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                             ON q.id = a.parent_Id\n                         WHERE q.tags LIKE '%bigquery%'\n                         GROUP BY a.owner_user_id\n                         \"\"\"\n\n# Set up the query (cancel the query if it would use too much of \n# your quota, with the limit set to 1 GB)\nsafe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)\nbigquery_experts_query_job = client.query(bigquery_experts_query, job_config=safe_config)\n\n# API request - run the query, and return a pandas DataFrame\nbigquery_experts_results = bigquery_experts_query_job.to_dataframe()\n\n```"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 6) Building a more generally useful service\n\nHow could you convert what you've done to a general function a website could call on the backend to get experts on any topic?  \n\nThink about it and then check the solution below."},{"metadata":{"trusted":true},"cell_type":"code","source":"q_6.solution()","execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 82, \"questionId\": \"6_GeneralizeExpertFinder\", \"learnToolsVersion\": \"0.2.13\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\ndef expert_finder(topic, client):\n    '''\n    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n\n    Inputs:\n        topic: A string with the topic of interest\n        client: A Client object that specifies the connection to the Stack Overflow dataset\n\n    Outputs:\n        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n    '''\n    my_query = \"\"\"\n               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                   ON q.id = a.parent_Id\n               WHERE q.tags like '%' + tag + '%'\n               GROUP BY a.owner_user_id\n               \"\"\"\n               \n    # Set up the query (a real service would have good error handling for \n    # queries that scan too much data)\n    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)      \n    my_query_job = client.query(my_query, job_config=safe_config)\n    \n    # API request - run the query, and return a pandas DataFrame\n    results = my_query_job.to_dataframe()\n\n    return results\n\n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\ndef expert_finder(topic, client):\n    '''\n    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n\n    Inputs:\n        topic: A string with the topic of interest\n        client: A Client object that specifies the connection to the Stack Overflow dataset\n\n    Outputs:\n        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n    '''\n    my_query = \"\"\"\n               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n                   ON q.id = a.parent_Id\n               WHERE q.tags like '%' + tag + '%'\n               GROUP BY a.owner_user_id\n               \"\"\"\n               \n    # Set up the query (a real service would have good error handling for \n    # queries that scan too much data)\n    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=1e9)      \n    my_query_job = client.query(my_query, job_config=safe_config)\n    \n    # API request - run the query, and return a pandas DataFrame\n    results = my_query_job.to_dataframe()\n\n    return results\n\n```"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Congratulations!\n\nYou know all the key components to use BigQuery and SQL effectively. Your SQL skills are sufficient to unlock many of the world's largest datasets.\n\nWant to go play with your new powers?  Kaggle has BigQuery datasets available [here](https://www.kaggle.com/datasets?sortBy=hottest&group=public&page=1&pageSize=20&size=sizeAll&filetype=fileTypeBigQuery).\n\n# Feedback\n\nBring any questions or feedback to the [Learn Discussion Forum](https://www.kaggle.com/learn-forum)."},{"metadata":{},"cell_type":"markdown","source":"---\n**[SQL Micro-Course Home Page](https://www.kaggle.com/learn/SQL)**\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}