{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/samplesub/Sample_Submissionb095668.csv\n",
      "/kaggle/input/amazon-hackerearth/test.csv\n",
      "/kaggle/input/amazon-hackerearth/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "# Note - this is for pytorch versions before 0.4\n",
    "# This is for accuracy in top 3 - you can change the first line to be whatever accuracy you want\n",
    "# def accuracy_topk(output, target, topk=(3,)):\n",
    "#     \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "#     maxk = max(topk)\n",
    "#     batch_size = target.size(0)\n",
    "\n",
    "#     _, pred = output.topk(maxk, 1, True, True)\n",
    "#     pred = pred.t()\n",
    "#     correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "#     res = []\n",
    "#     for k in topk:\n",
    "#         correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "#         res.append(correct_k.mul_(100.0 / batch_size))\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/amazon-hackerearth/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/amazon-hackerearth/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/samplesub/Sample_Submissionb095668.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did nothing for me, didn't help lost even with...</td>\n",
       "      <td>Useless</td>\n",
       "      <td>Shipment and delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did nothing for me, didn't help lost even with...</td>\n",
       "      <td>Useless</td>\n",
       "      <td>Not Effective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have bought these bags and  immediately open...</td>\n",
       "      <td>TRASH!!! Do not buy these bags it’s a waist of...</td>\n",
       "      <td>Customer Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gave me an allergic reaction on my face :(</td>\n",
       "      <td>Do not recommend</td>\n",
       "      <td>Allergic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>These don't compare to the name brand wipes. F...</td>\n",
       "      <td>Can't tackle big messes</td>\n",
       "      <td>Texture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  \\\n",
       "0  Did nothing for me, didn't help lost even with...   \n",
       "1  Did nothing for me, didn't help lost even with...   \n",
       "2  I have bought these bags and  immediately open...   \n",
       "3         Gave me an allergic reaction on my face :(   \n",
       "4  These don't compare to the name brand wipes. F...   \n",
       "\n",
       "                                        Review Title                  topic  \n",
       "0                                            Useless  Shipment and delivery  \n",
       "1                                            Useless          Not Effective  \n",
       "2  TRASH!!! Do not buy these bags it’s a waist of...       Customer Service  \n",
       "3                                   Do not recommend               Allergic  \n",
       "4                            Can't tackle big messes                Texture  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Review Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I use chia seed in my protein shakes. These ta...</td>\n",
       "      <td>Bad tast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I use chia seed in my protein shakes. These ta...</td>\n",
       "      <td>Bad tast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don’t waste your money.</td>\n",
       "      <td>No change. No results.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I use the book 'Fortify Your Life' by Tieraona...</td>\n",
       "      <td>Good Vegan Choice, Poor Non Vegan Choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I use the book 'Fortify Your Life' by Tieraona...</td>\n",
       "      <td>Good Vegan Choice, Poor Non Vegan Choice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review Text  \\\n",
       "0  I use chia seed in my protein shakes. These ta...   \n",
       "1  I use chia seed in my protein shakes. These ta...   \n",
       "2                            Don’t waste your money.   \n",
       "3  I use the book 'Fortify Your Life' by Tieraona...   \n",
       "4  I use the book 'Fortify Your Life' by Tieraona...   \n",
       "\n",
       "                               Review Title  \n",
       "0                                  Bad tast  \n",
       "1                                  Bad tast  \n",
       "2                    No change. No results.  \n",
       "3  Good Vegan Choice, Poor Non Vegan Choice  \n",
       "4  Good Vegan Choice, Poor Non Vegan Choice  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shipment and delivery', 'Not Effective', 'Customer Service',\n",
       "       'Allergic', 'Texture', 'Quality/Contaminated', 'Color and texture',\n",
       "       'Bad Taste/Flavor', 'Too big to swallow', 'Smells Bad',\n",
       "       'Too Sweet', 'Ingredients', 'Expiry', 'Packaging',\n",
       "       'Wrong Product received', 'Pricing', 'False Advertisement',\n",
       "       'Inferior to competitors', \"Didn't Like\", 'Customer Issues',\n",
       "       'Hard to Chew'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df['topic'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['rtext_len'] = train_df['Review Text'].apply(len)\n",
    "# train_df['rtitle_len'] = train_df['Review Title'].apply(len)\n",
    "# display(train_df.groupby('rtext_len').describe().sample(10))\n",
    "# display(train_df.groupby('rtitle_len').describe().sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Word Count - Total number of words in the headline\n",
    "    Character Count - Total number of characters in the headline excluding spaces\n",
    "    Word Density - Average length of the words used in the headline\n",
    "    Punctuation Count - Total number of punctuations used in the headline\n",
    "    Upper-Case to Lower-Case Words ratio - ratio of upper case words used and lower case words used in the text\n",
    "\n",
    "    Sentiment: Polarity - sentiment value of the headline computed using textblob package\n",
    "    Part of Speech: Nouns to Verbs Ratio - ratio of nouns and verbs used in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# cv = CountVectorizer(stop_words = 'english')\n",
    "# words = cv.fit_transform(data.verified_reviews)\n",
    "# sum_words = words.sum(axis=0)\n",
    "\n",
    "\n",
    "# words_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\n",
    "# words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "# frequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n",
    "\n",
    "# plt.style.use('fivethirtyeight')\n",
    "# color = plt.cm.ocean(np.linspace(0, 1, 20))\n",
    "# frequency.head(20).plot(x='word', y='freq', kind='bar', figsize=(15, 6), color = color)\n",
    "# plt.title(\"Most Frequently Occuring Words - Top 20\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "\n",
    "# wordcloud = WordCloud(background_color = 'lightcyan', width = 2000, height = 2000).generate_from_frequencies(dict(words_freq))\n",
    "\n",
    "# plt.style.use('fivethirtyeight')\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(wordcloud)\n",
    "# plt.title(\"Vocabulary from Reviews\", fontsize = 20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['word_count'] = df['Reviews Text'].apply(lambda x : len(x.split()))\n",
    "# df['char_count'] = df['headline_text'].apply(lambda x : len(x.replace(\" \",\"\")))\n",
    "# df['word_density'] = df['word_count'] / (df['char_count'] + 1)\n",
    "# df['punc_count'] = df['headline_text'].apply(lambda x : len([a for a in x if a in punc]))\n",
    "\n",
    "# df[['word_count', 'char_count', 'word_density', 'punc_count']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['text_title'] = train_df['Review Text'] + ' ' + train_df['Review Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "y = lbl_enc.fit_transform(train_df.topic.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.text_title.values, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape  (4767,)\n",
      "test shape (1192,)\n"
     ]
    }
   ],
   "source": [
    "print ('train shape ', xtrain.shape)\n",
    "print ('test shape', xvalid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always start with these features. They work (almost) everytime!\n",
    "tfv = TfidfVectorizer(min_df=2,  max_features=None, \n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "\n",
    "# Fitting TF-IDF to both training and test sets (semi-supervised learning)\n",
    "tfv.fit(list(xtrain) + list(xvalid))\n",
    "xtrain_tfv =  tfv.transform(xtrain) \n",
    "xvalid_tfv = tfv.transform(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #both preds and truths are same shape m by n (m is number of predictions and n is number of classes)\n",
    "# def top_n_accuracy(preds, truths, n):\n",
    "#     best_n = np.argsort(preds, axis=1)[:,-n:]\n",
    "#     ts = np.argmax(truths, axis=1)\n",
    "#     successes = 0\n",
    "#     for i in range(ts.shape[0]):\n",
    "#       if ts[i] in best_n[i,:]:\n",
    "#         successes += 1\n",
    "#     return float(successes)/ts.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4714765100671141\n"
     ]
    }
   ],
   "source": [
    "# Fitting a simple Logistic Regression on TFIDF\n",
    "clf = LogisticRegression(C=1.0)\n",
    "clf.fit(xtrain_tfv, ytrain)\n",
    "predictions = clf.predict(xvalid_tfv)\n",
    "\n",
    "print(metrics.accuracy_score(yvalid, predictions))\n",
    "# print(top_n_accuracy(predictions, yvalid, n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['text_title'] = test_df['Review Text'] + ' ' + test_df['Review Title']\n",
    "test_tfv = tfv.transform(test_df['text_title'].values)\n",
    "test_pred = clf.predict(test_tfv)\n",
    "test_df['topic'] = lbl_enc.inverse_transform(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = test_df[[\"Review Text\", \"Review Title\", \"topic\"]].copy()\n",
    "final.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
